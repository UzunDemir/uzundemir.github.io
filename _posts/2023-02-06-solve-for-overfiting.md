---
layout: post
title:  "Фундаментальные концепции переобучения и недообучения в машинном обучении."
---

Этот модуль дает интуитивно понятное введение в очень фундаментальные концепции переобучения и недообучения в машинном обучении.
Модели машинного обучения никогда не могут делать идеальные прогнозы: ошибка теста никогда не равна нулю. 
Этот провал происходит из-за фундаментального компромисса 
между гибкостью моделирования и ограниченным размером обучающего набора данных .

![Image alt]({{ site.baseurl }}//images/3.png)




Первая презентация определит эти проблемы и охарактеризует, как и почему они возникают.

Затем мы представим методологию количественной оценки этих проблем путем сравнения ошибки train с ошибкой test для различного выбора семейства моделей и параметров

модели. Что еще более важно, мы подчеркнем влияние размера обучающей выборки на этот компромисс .

Наконец, мы свяжем переоснащение и недообучение с понятиями статистической дисперсии и систематической ошибки.

Готовый ноутбук с датасетом - [здесь.](https://github.com/UzunDemir/SELECTING-THE-BEST-MODEL) 

